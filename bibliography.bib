@MASTERSTHESIS {,
    author = "Oleg Yarin",
    title  = "Development and Evaluation of a Visual Attention Model with Python and Tensorflow",
    school = "HTW Berlin",
    year   = "2017"
}
@article{Ba2015,
abstract = {We present an attention-based model for recognizing multiple objects in images. The proposed model is a deep recurrent neural network trained with reinforcement learning to attend to the most relevant regions of the input image. We show that the model learns to both localize and recognize multiple objects despite being given only class labels during training. We evaluate the model on the challenging task of transcribing house number sequences from Google Street View images and show that it is both more accurate than the state-of-the-art convolutional networks and uses fewer parameters and less computation.},
archivePrefix = {arXiv},
arxivId = {arXiv:1412.7755v2},
author = {Ba, Jimmy Lei and Mnih, Volodymyr and Kavukcuoglu, Koray},
eprint = {arXiv:1412.7755v2},
file = {:Users/olegya/Library/Application Support/Mendeley Desktop/Downloaded/Ba et al. - Unknown - MULTIPLE OBJECT RECOGNITION WITH VISUAL ATTENTION.pdf:pdf},
isbn = {9781424465163},
journal = {Iclr},
pages = {1--10},
title = {{Multiple Object Recognition With Visual Attention}},
url = {https://arxiv.org/pdf/1412.7755.pdf},
year = {2015}
}
@article{Mnih2014,
abstract = {Applying convolutional neural networks to large images is computationally expensive because the amount of computation scales linearly with the number of image pixels. We present a novel recurrent neural network model that is capable of extracting information from an image or video by adaptively selecting a sequence of regions or locations and only processing the selected regions at high resolution. Like convolutional neural networks, the proposed model has a degree of translation invariance built-in, but the amount of computation it performs can be controlled independently of the input image size. While the model is non-differentiable, it can be trained using reinforcement learning methods to learn task-specific policies. We evaluate our model on several image classification tasks, where it significantly outperforms a convolutional neural network baseline on cluttered images, and on a dynamic visual control problem, where it learns to track a simple object without an explicit training signal for doing so.},
archivePrefix = {arXiv},
arxivId = {1406.6247},
author = {Mnih, Volodymyr and Heess, Nicolas and Graves, Alex and Kavukcuoglu, Koray},
doi = {ng},
eprint = {1406.6247},
file = {:Users/olegya/Library/Application Support/Mendeley Desktop/Downloaded/Mnih et al. - 2014 - Recurrent Models of Visual Attention.pdf:pdf},
isbn = {078036404X},
issn = {0157244X},
journal = {Nips-2014},
keywords = {main work},
mendeley-tags = {main work},
month = {jun},
pages = {1--9},
title = {{Recurrent Models of Visual Attention}},
url = {http://arxiv.org/abs/1406.6247},
year = {2014}
}

@article{Goldsborough,
abstract = {— Deep learning is a branch of artificial intelligence employing deep neural network architectures that has signifi-cantly advanced the state-of-the-art in computer vision, speech recognition, natural language processing and other domains. In November 2015, Google released TensorFlow, an open source deep learning software library for defining, training and deploying machine learning models. In this paper, we review TensorFlow and put it in context of modern deep learning concepts and software. We discuss its basic computational paradigms and distributed execution model, its programming interface as well as accompanying visualization toolkits. We then compare Ten-sorFlow to alternative libraries such as Theano, Torch or Caffe on a qualitative as well as quantitative basis and finally comment on observed use-cases of TensorFlow in academia and industry.},
author = {Goldsborough, Peter},
file = {:Users/olegya/Library/Application Support/Mendeley Desktop/Downloaded/Goldsborough - Unknown - A Tour of TensorFlow Proseminar Data Mining.pdf:pdf},
keywords = {Distributed Computing,Index Terms— Artificial Intelligence,Machine Learning,Neu-ral Networks,Open source software,Software packages},
title = {{A Tour of TensorFlow Proseminar Data Mining}},
url = {https://arxiv.org/pdf/1610.01178.pdf}
}

@misc{CAMEL,
title = {{CAMELYON17 - Home}},
url = {https://camelyon17.grand-challenge.org/},
urldate = {2017-05-12}
}

@book{Goodfellow-et-al-2016,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    year={2016}
}
@book{Bishop2006,
abstract = {Predicting the binding mode of flexible polypeptides to proteins is an important task that falls outside the domain of applicability of most small molecule and protein−protein docking tools. Here, we test the small molecule flexible ligand docking program Glide on a set of 19 non-$\alpha$-helical peptides and systematically improve pose prediction accuracy by enhancing Glide sampling for flexible polypeptides. In addition, scoring of the poses was improved by post-processing with physics-based implicit solvent MM- GBSA calculations. Using the best RMSD among the top 10 scoring poses as a metric, the success rate (RMSD ≤ 2.0 {\AA} for the interface backbone atoms) increased from 21{\%} with default Glide SP settings to 58{\%} with the enhanced peptide sampling and scoring protocol in the case of redocking to the native protein structure. This approaches the accuracy of the recently developed Rosetta FlexPepDock method (63{\%} success for these 19 peptides) while being over 100 times faster. Cross-docking was performed for a subset of cases where an unbound receptor structure was available, and in that case, 40{\%} of peptides were docked successfully. We analyze the results and find that the optimized polypeptide protocol is most accurate for extended peptides of limited size and number of formal charges, defining a domain of applicability for this approach.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Bishop, Christopher M},
booktitle = {Springer Science+Business Media},
doi = {10.1017/CBO9781107415324.004},
eprint = {arXiv:1011.1669v3},
file = {:Users/olegya/Library/Application Support/Mendeley Desktop/Downloaded/Unknown - Unknown - full-text.pdf:pdf},
isbn = {9788578110796},
issn = {1098-6596},
keywords = {icle},
number = {9},
pages = {1689--1699},
pmid = {25246403},
title = {{Pattern Recognition and Machine Learning}},
volume = {53},
year = {2006}
}

@article{Krizhevsky2012,
abstract = {We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSRVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5{\%} and 17.0{\%} which is considerably better than the previous state of the art. The neural network, which has 60 million paramters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolutional operation. To reduce overfitting in the fully-connected layers, we employed a recently-developed method called 'dropout' that proved to be effective. We also entered a variant of the model in the ILSVRC-2012 competition and achievd a top-5 test error rate of 15.3{\%}, compared to 26.2{\%} achieved by the second-best entry.},
archivePrefix = {arXiv},
arxivId = {1102.0183},
author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
doi = {http://dx.doi.org/10.1016/j.protcy.2014.09.007},
eprint = {1102.0183},
file = {:Users/olegya/Library/Application Support/Mendeley Desktop/Downloaded/Krizhevsky, Sutskever, Hinton - 2012 - ImageNet Classification with Deep Convolutional Neural Networks.pdf:pdf},
isbn = {9781627480031},
issn = {10495258},
journal = {Advances In Neural Information Processing Systems},
pages = {1--9},
pmid = {7491034},
title = {{ImageNet Classification with Deep Convolutional Neural Networks}},
url = {https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks},
year = {2012}
}
