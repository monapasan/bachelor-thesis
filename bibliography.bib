@MASTERSTHESIS {,
    author = "Oleg Yarin",
    title  = "Development and Evaluation of a Visual Attention Model with Python and Tensorflow",
    school = "HTW Berlin",
    year   = "2017"
}
@article{Ba2015,
abstract = {We present an attention-based model for recognizing multiple objects in images. The proposed model is a deep recurrent neural network trained with reinforcement learning to attend to the most relevant regions of the input image. We show that the model learns to both localize and recognize multiple objects despite being given only class labels during training. We evaluate the model on the challenging task of transcribing house number sequences from Google Street View images and show that it is both more accurate than the state-of-the-art convolutional networks and uses fewer parameters and less computation.},
archivePrefix = {arXiv},
arxivId = {arXiv:1412.7755v2},
author = {Ba, Jimmy Lei and Mnih, Volodymyr and Kavukcuoglu, Koray},
eprint = {arXiv:1412.7755v2},
file = {:Users/olegya/Library/Application Support/Mendeley Desktop/Downloaded/Ba et al. - Unknown - MULTIPLE OBJECT RECOGNITION WITH VISUAL ATTENTION.pdf:pdf},
isbn = {9781424465163},
journal = {Iclr},
pages = {1--10},
title = {{Multiple Object Recognition With Visual Attention}},
url = {https://arxiv.org/pdf/1412.7755.pdf},
year = {2015}
}
@article{Mnih2014,
abstract = {Applying convolutional neural networks to large images is computationally expensive because the amount of computation scales linearly with the number of image pixels. We present a novel recurrent neural network model that is capable of extracting information from an image or video by adaptively selecting a sequence of regions or locations and only processing the selected regions at high resolution. Like convolutional neural networks, the proposed model has a degree of translation invariance built-in, but the amount of computation it performs can be controlled independently of the input image size. While the model is non-differentiable, it can be trained using reinforcement learning methods to learn task-specific policies. We evaluate our model on several image classification tasks, where it significantly outperforms a convolutional neural network baseline on cluttered images, and on a dynamic visual control problem, where it learns to track a simple object without an explicit training signal for doing so.},
archivePrefix = {arXiv},
arxivId = {1406.6247},
author = {Mnih, Volodymyr and Heess, Nicolas and Graves, Alex and Kavukcuoglu, Koray},
doi = {ng},
eprint = {1406.6247},
file = {:Users/olegya/Library/Application Support/Mendeley Desktop/Downloaded/Mnih et al. - 2014 - Recurrent Models of Visual Attention.pdf:pdf},
isbn = {078036404X},
issn = {0157244X},
journal = {Nips-2014},
keywords = {main work},
mendeley-tags = {main work},
month = {jun},
pages = {1--9},
title = {{Recurrent Models of Visual Attention}},
url = {http://arxiv.org/abs/1406.6247},
year = {2014}
}

@article{Goldsborough,
abstract = {— Deep learning is a branch of artificial intelligence employing deep neural network architectures that has signifi-cantly advanced the state-of-the-art in computer vision, speech recognition, natural language processing and other domains. In November 2015, Google released TensorFlow, an open source deep learning software library for defining, training and deploying machine learning models. In this paper, we review TensorFlow and put it in context of modern deep learning concepts and software. We discuss its basic computational paradigms and distributed execution model, its programming interface as well as accompanying visualization toolkits. We then compare Ten-sorFlow to alternative libraries such as Theano, Torch or Caffe on a qualitative as well as quantitative basis and finally comment on observed use-cases of TensorFlow in academia and industry.},
author = {Goldsborough, Peter},
file = {:Users/olegya/Library/Application Support/Mendeley Desktop/Downloaded/Goldsborough - Unknown - A Tour of TensorFlow Proseminar Data Mining.pdf:pdf},
keywords = {Distributed Computing,Index Terms— Artificial Intelligence,Machine Learning,Neu-ral Networks,Open source software,Software packages},
title = {{A Tour of TensorFlow Proseminar Data Mining}},
url = {https://arxiv.org/pdf/1610.01178.pdf}
}

@misc{CAMEL,
title = {{CAMELYON17 - Home}},
url = {https://camelyon17.grand-challenge.org/},
urldate = {2017-05-12}
}

@book{Goodfellow-et-al-2016,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    year={2016}
}
@book{Bishop2006,
abstract = {Predicting the binding mode of flexible polypeptides to proteins is an important task that falls outside the domain of applicability of most small molecule and protein−protein docking tools. Here, we test the small molecule flexible ligand docking program Glide on a set of 19 non-$\alpha$-helical peptides and systematically improve pose prediction accuracy by enhancing Glide sampling for flexible polypeptides. In addition, scoring of the poses was improved by post-processing with physics-based implicit solvent MM- GBSA calculations. Using the best RMSD among the top 10 scoring poses as a metric, the success rate (RMSD ≤ 2.0 {\AA} for the interface backbone atoms) increased from 21{\%} with default Glide SP settings to 58{\%} with the enhanced peptide sampling and scoring protocol in the case of redocking to the native protein structure. This approaches the accuracy of the recently developed Rosetta FlexPepDock method (63{\%} success for these 19 peptides) while being over 100 times faster. Cross-docking was performed for a subset of cases where an unbound receptor structure was available, and in that case, 40{\%} of peptides were docked successfully. We analyze the results and find that the optimized polypeptide protocol is most accurate for extended peptides of limited size and number of formal charges, defining a domain of applicability for this approach.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Bishop, Christopher M},
booktitle = {Springer Science+Business Media},
doi = {10.1017/CBO9781107415324.004},
eprint = {arXiv:1011.1669v3},
file = {:Users/olegya/Library/Application Support/Mendeley Desktop/Downloaded/Unknown - Unknown - full-text.pdf:pdf},
isbn = {9788578110796},
issn = {1098-6596},
keywords = {icle},
number = {9},
pages = {1689--1699},
pmid = {25246403},
title = {{Pattern Recognition and Machine Learning}},
volume = {53},
year = {2006}
}

@article{Krizhevsky2012,
abstract = {We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSRVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5{\%} and 17.0{\%} which is considerably better than the previous state of the art. The neural network, which has 60 million paramters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolutional operation. To reduce overfitting in the fully-connected layers, we employed a recently-developed method called 'dropout' that proved to be effective. We also entered a variant of the model in the ILSVRC-2012 competition and achievd a top-5 test error rate of 15.3{\%}, compared to 26.2{\%} achieved by the second-best entry.},
archivePrefix = {arXiv},
arxivId = {1102.0183},
author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
doi = {http://dx.doi.org/10.1016/j.protcy.2014.09.007},
eprint = {1102.0183},
file = {:Users/olegya/Library/Application Support/Mendeley Desktop/Downloaded/Krizhevsky, Sutskever, Hinton - 2012 - ImageNet Classification with Deep Convolutional Neural Networks.pdf:pdf},
isbn = {9781627480031},
issn = {10495258},
journal = {Advances In Neural Information Processing Systems},
pages = {1--9},
pmid = {7491034},
title = {{ImageNet Classification with Deep Convolutional Neural Networks}},
url = {https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks},
year = {2012}
}

@Book{ Kriesel2007NeuralNetworks,
   author = { David Kriesel },
   title =  { A Brief Introduction to Neural Networks },
   year =   { 2007 },
   url =   { available at http://www.dkriesel.com }
}

@misc{Nielsen2015,
author = {Nielsen, Michael A.},
publisher = {Determination Press},
title = {{Neural Networks and Deep Learning}},
url = {http://neuralnetworksanddeeplearning.com/},
year = {2015}
}

@book{VanDerSmagt1996,
author = {{Van Der Smagt}, Patrick and Krose, Ben and Krr, Ben and {An Der Smagt}, Patrick V},
edition = {8},
file = {:Users/olegya/Library/Application Support/Mendeley Desktop/Downloaded/Van Der Smagt et al. - 1996 - An introduction to Neural Networks.pdf:pdf},
publisher = {University of Amsterdam},
title = {{An introduction to Neural Networks}},
url = {http://www.fwi.uva.nl/research/neuro/ http://www.fwi.uva.nl/research/neuro/},
year = {1996}
}

@article{Bishop1995,
abstract = {This book provides a solid statistical foundation for neural networks from a pattern recognition perspective. The focus is on the types of neural nets that are most widely used in practical applications, such as the multi-layer perceptron and radial basis function networks. Rather than trying to cover many different types of neural networks, Bishop thoroughly covers topics such as density estimation, error functions, parameter optimization algorithms, data pre-processing, and Bayesian methods. All topics are organized well and all mathematical foundations are explained before being applied to neural networks. The text is suitable for a graduate or advanced undergraduate level course on neural networks or for practitioners interested in applying neural networks to real-world problems. The reader is assumed to have the level of math knowledge necessary for an undergraduate science degree. This is the first comprehensive treatment of feed-forward neural networks from the perspective of statistical pattern recognition. After introducing the basic concepts, the book examines techniques for modelling probability density functions and the properties and merits of the multi-layer perceptron and radial basis function network models. Also covered are various forms of error functions, principal algorithms for error function minimalization, learning and generalization in neural networks, and Bayesian techniques and their applications. Designed as a text, with over 100 exercises, this fully up-to-date work will benefit anyone involved in the fields of neural computation and pattern recognition.},
archivePrefix = {arXiv},
arxivId = {0-387-31073-8},
author = {Bishop, C M},
doi = {10.2307/2965437},
eprint = {0-387-31073-8},
file = {:Users/olegya/Library/Application Support/Mendeley Desktop/Downloaded/Bishop - Unknown - Neural Networks for Pattern Recognition.pdf:pdf},
isbn = {0198538642},
issn = {01621459},
journal = {Journal of the American Statistical Association},
pages = {482},
pmid = {1144972},
title = {{Neural networks for pattern recognition}},
url = {http://cs.du.edu/{~}mitchell/mario{\_}books/Neural{\_}Networks{\_}for{\_}Pattern{\_}Recognition{\_}-{\_}Christopher{\_}Bishop.pdf},
volume = {92},
year = {1995}
}

@book{rosenblatt1962principles,
  title={Principles of neurodynamics: perceptrons and the theory of brain mechanisms},
  author={Rosenblatt, F.},
  lccn={62012882},
  series={Report (Cornell Aeronautical Laboratory)},
  url={https://books.google.ca/books?id=7FhRAAAAMAAJ},
  year={1962},
  publisher={Spartan Books}
}

@misc{KarpathyAndrej2016,
author = {{Karpathy Andrej}},
booktitle = {Standord University},
title = {{CS231n Convolutional Neural Networks for Visual Recognition}},
url = {http://cs231n.github.io/optimization-1/},
urldate = {2017-06-04},
year = {2016}
}
\

@article{Rumelhart1986,
author = {Rumelhart, David E. and Hinton, Geoffrey E. and Williams, Ronald J.},
doi = {10.1038/323533a0},
issn = {0028-0836},
journal = {Nature},
month = {oct},
number = {6088},
pages = {533--536},
publisher = {Nature Publishing Group},
title = {{Learning representations by back-propagating errors}},
url = {http://www.nature.com/doifinder/10.1038/323533a0},
volume = {323},
year = {1986}
}

@misc{ColahChristopher2015,
author = {{Colah Christopher}},
title = {{Understanding LSTM Networks -- colah's blog}},
url = {http://colah.github.io/posts/2015-08-Understanding-LSTMs/},
urldate = {2017-06-04},
year = {2015}
}

@phdthesis{Hochreiter1991,
abstract = {Ich versichere, da{\ss} ich diese Diplomarbeit selbst{\"{a}}ndig verfa{\ss}t und keine anderen als die ange-geben Quellen und Hilfsmittel benutzt habe.},
author = {Hochreiter, Josef},
booktitle = {Master's thesis, Institut fur Informatik, Technische Universitat, Munchen},
pages = {1--71},
title = {{Untersuchungen zu dynamischen neuronalen Netzen}},
url = {http://people.idsia.ch/{~}juergen/SeppHochreiter1991ThesisAdvisorSchmidhuber.pdf http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:Untersuchungen+zu+dynamischen+neuronalen+Netzen{\#}0},
year = {1991}
}

@article{Hochreiter:1997:LSM:1246443.1246450,
 author = {Hochreiter, Sepp and Schmidhuber, J\"{u}rgen},
 title = {Long Short-Term Memory},
 journal = {Neural Comput.},
 issue_date = {November 15, 1997},
 volume = {9},
 number = {8},
 month = nov,
 year = {1997},
 issn = {0899-7667},
 pages = {1735--1780},
 numpages = {46},
 url = {http://dx.doi.org/10.1162/neco.1997.9.8.1735},
 doi = {10.1162/neco.1997.9.8.1735},
 acmid = {1246450},
 publisher = {MIT Press},
 address = {Cambridge, MA, USA},
}
@article{Elman1990,
abstract = {[PDF]},
author = {Elman, Jeffrey L},
doi = {10.1207/s15516709cog1402_1},
isbn = {1551-6709},
issn = {03640213},
journal = {Cognitive science},
number = {2},
pages = {179--211},
pmid = {19563812},
title = {{Finding structure in time}},
url = {https://pdfs.semanticscholar.org/4eb9/43bf999ce49e5ebb629d7d0ffee44becff94.pdf},
volume = {14},
year = {1990}
}

@inproceedings{werbos:bptt,
  added-at = {2008-03-11T14:52:34.000+0100},
  author = {Werbos, P.},
  biburl = {https://www.bibsonomy.org/bibtex/2062450f0f2629f8746f7c0e54922b0cc/idsia},
  booktitle = {Proceedings of IEEE},
  citeulike-article-id = {2380325},
  interhash = {00557ce797fc197789230a80f431dc10},
  intrahash = {062450f0f2629f8746f7c0e54922b0cc},
  keywords = {inaki},
  number = 10,
  pages = {1550--1560},
  priority = {2},
  timestamp = {2008-03-11T14:56:15.000+0100},
  title = {Backpropagation through time: what does it do and how to do it},
  volume = 78,
  year = 1990
}

@article{mnih2013playing,
  title={Playing atari with deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1312.5602},
  year={2013}
}

@article{Sutton2012,
author = {Sutton, Richard S and Barto, Andrew G},
file = {:Users/olegya/Library/Application Support/Mendeley Desktop/Downloaded/Sutton, Barto - Unknown - Reinforcement Learning An Introduction.pdf:pdf},
title = {{Reinforcement Learning: An Introduction}},
url = {http://people.inf.elte.hu/lorincz/Files/RL{\_}2006/SuttonBook.pdf},
year = {2012}
}


@article{Larochelle2010,
abstract = {We describe a model based on a Boltzmann machine with third - order connections that can learn how to accumulate information about a shape over several fixations. The model uses a retina that only has enough high resolution pixels to cover a small area of the image, so it must ...},
author = {Larochelle, Hugo and Hinton, Geoffrey},
doi = {10.1371/journal.pone.0003290},
file = {:Users/olegya/Library/Application Support/Mendeley Desktop/Downloaded/Larochelle, Hinton - 2010 - Learning to combine foveal glimpses with a third-order Boltzmann machine.pdf:pdf},
isbn = {9781617823800},
issn = {1932-6203},
journal = {Nips-2010},
pages = {1243--1251},
pmid = {18820727},
title = {{Learning to combine foveal glimpses with a third-order Boltzmann machine}},
url = {papers2://publication/uuid/4E7CE0E0-C8F9-49B9-9B45-051B57B8DDF5{\%}5Cnpapers2://publication/uuid/6610B2C4-A06C-4AD7-9041-5557B73F415D},
year = {2010}
}
